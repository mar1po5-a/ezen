{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz/3PXt1UdxyhkMQrSoSP0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mar1po5-a/ezen/blob/main/ChromaDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CInqCXygypmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c40d945-ed04-4d2f-c960-d4c39bcd4084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain-google-genai\n",
        "!pip install -q langchain langchain-community chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "7LrGj3lRy6Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gemini API 키 비밀관리 설정 후 진행\n",
        "# userdata.get() -> 저장된 비밀 값을 안전하게 불러옴\n",
        "try:\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "except userdata.SecretNotFoundError:\n",
        "  print(\"ERROR: GOOGLE_API_KEY not found in Colab secrets. Pleas set it.\")"
      ],
      "metadata": {
        "id": "l7AmjzcOzePo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 임베딩 모델\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "# 벡터 DB\n",
        "from langchain_community.vectorstores import Chroma\n",
        "# 문서 표현\n",
        "from langchain_core.documents import Document\n",
        "# 텍스트 크기 분할\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# 프롬프트 생성\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "# 체인 내에서 데이터를 그대로 전달\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "# LLM 출력을 문자열로 변환\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "mm6HHATB03uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 데이터\n",
        "documents_data = [\n",
        "    \"대한민국의 수도는 서울입니다. 서울은 역사와 현대가 공존하는 도시입니다.\",\n",
        "    \"제주도는 아름다운 자연 경관으로 유명한 대한민국의 섬입니다. 한라산 국립공원이 대표적입니다.\",\n",
        "    \"부산은 대한민국 제2의 도시이자 최대 항구 도시입니다. 해운대 해수욕장이 유명합니다.\",\n",
        "    \"인공지능(AI)은 인간의 학습능력, 추론능력, 지각능력 등을 컴퓨터 프로그램을 통해 구현하는 기술입니다.\",\n",
        "    \"머신러닝은 인공지능의 한 분야로, 컴퓨터가 데이터를 통해 스스로 학습하고 예측하는 기술입니다.\"\n",
        "    \"1. 청년내일채움공제 \\\n",
        "[지원조건]\\\n",
        "중소기업에 정규직으로 취업한 청년에 해당하는 사람 [수령금액] 1,500만 원을 수령하게 됩니다.\"\n",
        "]"
      ],
      "metadata": {
        "id": "gxgTNet92BLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 데이터를 Document 객체로 변환\n",
        "# page_context와 metadata를 가짐\n",
        "docs = [Document(page_content=text, metadata={\"source\": f\"doc_{i+1}\"})\n",
        "for i, text in enumerate(documents_data)]\n",
        "\n",
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFkvFq532HtB",
        "outputId": "3896373e-fedb-4ab6-eae3-848a24359a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'doc_1'}, page_content='대한민국의 수도는 서울입니다. 서울은 역사와 현대가 공존하는 도시입니다.'), Document(metadata={'source': 'doc_2'}, page_content='제주도는 아름다운 자연 경관으로 유명한 대한민국의 섬입니다. 한라산 국립공원이 대표적입니다.'), Document(metadata={'source': 'doc_3'}, page_content='부산은 대한민국 제2의 도시이자 최대 항구 도시입니다. 해운대 해수욕장이 유명합니다.'), Document(metadata={'source': 'doc_4'}, page_content='인공지능(AI)은 인간의 학습능력, 추론능력, 지각능력 등을 컴퓨터 프로그램을 통해 구현하는 기술입니다.'), Document(metadata={'source': 'doc_5'}, page_content='머신러닝은 인공지능의 한 분야로, 컴퓨터가 데이터를 통해 스스로 학습하고 예측하는 기술입니다.1. 청년내일채움공제 [지원조건]중소기업에 정규직으로 취업한 청년에 해당하는 사람 [수령금액] 1,500만 원을 수령하게 됩니다.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검색 정확도를 높이고, 토큰을 효율적으로 활용하기 위해 chunk 단위로 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 200, # 각 청크의 크기\n",
        "    chunk_overlap = 20 # 청크 간 중복되는 글자 수\n",
        ")\n",
        "# split_documents -> 그냥 변수명\n",
        "# .split_documents() -> method\n",
        "split_documents = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"원본 문서 개수: {len(docs)}\")\n",
        "print(f\"분할된 청크 개수: {len(split_documents)}\")\n",
        "# print(\"\\n분할된 첫 번째 청크 예시:\")\n",
        "print(split_documents[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DguRwMds20l2",
        "outputId": "693c6ab7-e48d-4867-ab73-73f42ba66acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 문서 개수: 5\n",
            "분할된 청크 개수: 5\n",
            "page_content='대한민국의 수도는 서울입니다. 서울은 역사와 현대가 공존하는 도시입니다.' metadata={'source': 'doc_1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임베딩 모델 초기화\n",
        "# models/text_embedding-004 -> 최신 고성능 임베딩 모델\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "\n",
        "# llm 초기화\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash-latest\",\n",
        "    temperature=0.3 # 창의성\n",
        "    # 시스템 프롬프트를 사용자 프롬프트 형태로 변환하여 전달\n",
        "    # API 호환성과 model의 특성에 따라 유동적으로 선택하는 옵션\n",
        "    # convert_system_message_to_human=True\n",
        ")\n",
        "\n",
        "print(\"Gemini 임베딩 모델 및 LLM이 성공적으로 초기화되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVD1CkM63lOb",
        "outputId": "41447aa1-8366-4a9e-da37-18305b67ec15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini 임베딩 모델 및 LLM이 성공적으로 초기화되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터 저장소 생성\n",
        "# Chorma.from_documents()는 모든 작업을 한 번에 수행\n",
        "# 1. 문서 청크를 임베딩 모델을 사용해 벡터로 변환\n",
        "# 2. 벡터와 원본 텍스트, 메타 데이터를 ChromaDB에 저장\n",
        "# persist_directory를 지정하면 해당 경로에 DB 파일이 저장됨. -> 재사용 가능\n",
        "vectorstore_path = \"./chroma_db_rag_store\"\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=split_documents, # 분할된 문서\n",
        "    embedding=embeddings, # 임베딩 모델\n",
        "    # persist : 지속하다\n",
        "    persist_directory=vectorstore_path # DB 저장할 디렉토리\n",
        ")\n",
        "\n",
        "# 저장된 DB를 다시 로드할 때 사용 (재생성 x)\n",
        "# vectorstore = Chroma(persist_directory=vectorstore_path, embedding_function=embeddings)\n",
        "\n",
        "print(f\"문서들이 ChromaDB에 성공적으로 임베딩 및 저장되었습니다. (저장 경로: {vectorstore_path})\")\n",
        "# 기존의 RDB : table / Vector DB : collection\n",
        "print(f\"ChromaDB에 저장된 총 벡터(청크) 수: {vectorstore._collection.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpgByCYp5PUJ",
        "outputId": "f6250689-6e35-4f74-978f-c7ee8bc22ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서들이 ChromaDB에 성공적으로 임베딩 및 저장되었습니다. (저장 경로: ./chroma_db_rag_store)\n",
            "ChromaDB에 저장된 총 벡터(청크) 수: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터 저장소에서 유사도 높은 문서를 검색하는 검색기 생성\n",
        "# retriever : 되찾다, 회수하다\n",
        "# k=3은 가장 유사한 문서 3개를 가져오도록 설정\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# 검색기 테스트\n",
        "query_test = \"대한민국의 수도는 어디인가요?\"\n",
        "retrieved_docs_test = retriever.invoke(query_test)\n",
        "print(f\"'{query_test}'에 대한 검색 결과 (상위 {len(retrieved_docs_test)}개)\")\n",
        "for i, doc in enumerate(retrieved_docs_test):\n",
        "  # 메타데이터 중 source를 가져오되, 존재하지 않으면 기본 값을 가져옴\n",
        "  print(f\" {i+1}, {doc.page_content} (출처: {doc.metadata.get('source', 'N/A')})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euRf3JhX8dE3",
        "outputId": "6ec81970-306e-4885-812e-8e3d8b8c0683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'대한민국의 수도는 어디인가요?'에 대한 검색 결과 (상위 3개)\n",
            " 1, 대한민국의 수도는 서울입니다. 서울은 역사와 현대가 공존하는 도시입니다. (출처: doc_1)\n",
            " 2, 대한민국의 수도는 서울입니다. 서울은 역사와 현대가 공존하는 도시입니다. (출처: doc_1)\n",
            " 3, 제주도는 아름다운 자연 경관으로 유명한 대한민국의 섬입니다. 한라산 국립공원이 대표적입니다. (출처: doc_2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG 파이프라인 구성 : 정보 검색 - 문맥 정보 준비 - 프롬프트 구성\n",
        "# - 답변 생성 및 출력 일련의 과정이 파이프라인\n",
        "\n",
        "# 프롬프트 템플릿 정의\n",
        "# {context} : 검색된 문서 내용, {question} : 사용자 질\n",
        "prompt_template = \"\"\"당신은 질문에 친절하고 상세하게 답변하는 AI 어시스턴트입니다.\n",
        "주어진 문맥(context) 정보를 바탕으로 질문에 답변해주세요. 문맥에서 답을 찾을 수 없다면, \"제공된 정보만으로는 답변하기 어렵습니다.\"라고 솔직하게 말해주세요.\n",
        "\n",
        "문맥:\n",
        "{context}\n",
        "\n",
        "질문:\n",
        "{question}\n",
        "\n",
        "답변:\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "\n",
        "# RAG 체인 정의\n",
        "# retriever로 문서를 검색하고\n",
        "# 검색된 문서들의 page_content를 하나의 문자열로 합\n",
        "# LCEL 사용 : |(파이프 기호)의 사용, 파이프라인 또는 체인을 더 쉽고 유연하게 구성하는 방식\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | (lambda docs: \"\\n\\n\".join(d.page_content for d in docs)),\n",
        "    # RunnablePassthrough.assian() : 체인 내에서 새로운 키를 생성하고 값을 할당\n",
        "     # question에 초기 입력을 그대로 할당하기 위해 키:값으로 세팅\n",
        "     \"question\": RunnablePassthrough()}\n",
        "      | prompt\n",
        "      | llm\n",
        "      | StrOutputParser() # llm 출력을 일반 문자열로 변환\n",
        ")\n",
        "\n",
        "print(\"RAG 체인이 성공적으로 구성되었습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r3gHI8aFIj2",
        "outputId": "12fb110f-77a5-4ab9-a6a0-6a2ad7032494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG 체인이 성공적으로 구성되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG 체인에 질문을 입력하여 답변 생성\n",
        "\n",
        "question1 = \"대한민국의 수도는 어디이고, 그 도시는 어떤 특징이 있나요?\"\n",
        "print(f\"\\n[질문 1]: {question1}\")\n",
        "answer1 = rag_chain.invoke(question1)\n",
        "print(f\"[답변 1]: {answer1}\")\n",
        "\n",
        "question2 = \"AI 기술에 대해 설명해주세요.\"\n",
        "print(f\"\\n[질문 2]: {question2}\")\n",
        "answer2 = rag_chain.invoke(question2)\n",
        "print(f\"[답변 2]: {answer2}\")\n",
        "\n",
        "question3 = \"부산의 유명한 음식은 무엇인가요?\" # 샘플 문서에 없는 내용\n",
        "print(f\"\\n[질문 3]: {question3}\")\n",
        "answer3 = rag_chain.invoke(question3)\n",
        "print(f\"[답변 3]: {answer3}\")\n",
        "\n",
        "question4 = \"청년내일채움공제 지원조건 \" # 샘플 문서에 없는 내용\n",
        "print(f\"\\n[질문 4]: {question4}\")\n",
        "answer4 = rag_chain.invoke(question4)\n",
        "print(f\"[답변 4]: {answer4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOZDvGkOHxIs",
        "outputId": "0ea2467d-f934-4159-d0d3-ca73e646bd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[질문 1]: 대한민국의 수도는 어디이고, 그 도시는 어떤 특징이 있나요?\n",
            "[답변 1]: 대한민국의 수도는 서울입니다.  서울은 역사와 현대가 공존하는 도시라는 특징이 있습니다.\n",
            "\n",
            "[질문 2]: AI 기술에 대해 설명해주세요.\n",
            "[답변 2]: AI 기술은 인간의 학습능력, 추론능력, 그리고 지각능력을 컴퓨터 프로그램을 통해 구현하는 기술입니다.  즉, 인간이 하는 것처럼 배우고, 추론하고, 세상을 인지하는 능력을 컴퓨터 시스템에 부여하는 것을 목표로 합니다.\n",
            "\n",
            "[질문 3]: 부산의 유명한 음식은 무엇인가요?\n",
            "[답변 3]: 제공된 정보만으로는 답변하기 어렵습니다.  제공된 문맥에는 서울과 제주도에 대한 정보만 있고, 부산에 대한 정보는 없습니다.\n",
            "\n",
            "[질문 4]: 청년내일채움공제 지원조건 \n",
            "[답변 4]: 제공된 정보만으로는 답변하기 어렵습니다.  제공된 문맥은 대한민국의 수도와 제주도에 대한 정보만 담고 있고, 청년내일채움공제 지원조건에 대한 내용은 포함되어 있지 않습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ChromaDB 파일 정리\n",
        "# 해당 코드 실행 시 vectorstore_path에 저장된 DB 데이터가 삭제됨\n",
        "\n",
        "import shutil\n",
        "\n",
        "try:\n",
        "  # vectorstore 객체가 존재하면 컬렉션 먼저 삭제 시도\n",
        "  if 'vectorstore' in globals() and vectorstore is not None:\n",
        "    print(f\"'{vectorstore_path}' 디렉토리를 삭제하여 ChromaDB 데이터를 정리합니다.\")\n",
        "    shutil.rmtree(vectorstore_path)\n",
        "    print(\"ChromaDB 데이터 정리가 완료되었습니다.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"'{vectorstore_path}' 디렉토리가 이미 존재하지 않습니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"ChromaDB 데이터 정리 중 오류 발생: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM293Gy7IShH",
        "outputId": "a9f99a61-6989-4d3e-eb86-3ccd613009e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'./chroma_db_rag_store' 디렉토리를 삭제하여 ChromaDB 데이터를 정리합니다.\n",
            "ChromaDB 데이터 정리가 완료되었습니다.\n"
          ]
        }
      ]
    }
  ]
}